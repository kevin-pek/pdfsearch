program(1.0)
[buildInfo = dict<tensor<string, []>, tensor<string, []>>({{"coremlc-component-MIL", "4.28.4"}, {"coremlc-version", "1436.100.10"}, {"coremltools-component-torch", "2.0.0"}, {"coremltools-version", "7.0"}})]
{
    func main<ios15>(tensor<int32, [1, 128]> attention_mask, tensor<int32, [1, 128]> input_ids) {
            tensor<fp32, [30528, 512]> model_embeddings_word_embeddings_weight = const()[name = tensor<string, []>("model_embeddings_word_embeddings_weight"), val = tensor<fp32, [30528, 512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(64)))];
            tensor<fp32, [512]> model_embeddings_LayerNorm_bias = const()[name = tensor<string, []>("model_embeddings_LayerNorm_bias"), val = tensor<fp32, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(62521472)))];
            tensor<fp32, [512]> model_embeddings_LayerNorm_weight = const()[name = tensor<string, []>("model_embeddings_LayerNorm_weight"), val = tensor<fp32, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(62523584)))];
            tensor<fp32, [512]> model_encoder_layer_0_attention_self_query_bias = const()[name = tensor<string, []>("model_encoder_layer_0_attention_self_query_bias"), val = tensor<fp32, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(62525696)))];
            tensor<fp32, [512, 512]> model_encoder_layer_0_attention_self_query_weight = const()[name = tensor<string, []>("model_encoder_layer_0_attention_self_query_weight"), val = tensor<fp32, [512, 512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(62527808)))];
            tensor<fp32, [512]> model_encoder_layer_0_attention_self_key_bias = const()[name = tensor<string, []>("model_encoder_layer_0_attention_self_key_bias"), val = tensor<fp32, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(63576448)))];
            tensor<fp32, [512, 512]> model_encoder_layer_0_attention_self_key_weight = const()[name = tensor<string, []>("model_encoder_layer_0_attention_self_key_weight"), val = tensor<fp32, [512, 512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(63578560)))];
            tensor<fp32, [512]> model_encoder_layer_0_attention_self_value_bias = const()[name = tensor<string, []>("model_encoder_layer_0_attention_self_value_bias"), val = tensor<fp32, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(64627200)))];
            tensor<fp32, [512, 512]> model_encoder_layer_0_attention_self_value_weight = const()[name = tensor<string, []>("model_encoder_layer_0_attention_self_value_weight"), val = tensor<fp32, [512, 512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(64629312)))];
            tensor<fp32, [512]> model_encoder_layer_0_attention_output_dense_bias = const()[name = tensor<string, []>("model_encoder_layer_0_attention_output_dense_bias"), val = tensor<fp32, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(65677952)))];
            tensor<fp32, [512, 512]> model_encoder_layer_0_attention_output_dense_weight = const()[name = tensor<string, []>("model_encoder_layer_0_attention_output_dense_weight"), val = tensor<fp32, [512, 512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(65680064)))];
            tensor<fp32, [512]> model_encoder_layer_0_attention_output_LayerNorm_bias = const()[name = tensor<string, []>("model_encoder_layer_0_attention_output_LayerNorm_bias"), val = tensor<fp32, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(66728704)))];
            tensor<fp32, [512]> model_encoder_layer_0_attention_output_LayerNorm_weight = const()[name = tensor<string, []>("model_encoder_layer_0_attention_output_LayerNorm_weight"), val = tensor<fp32, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(66730816)))];
            tensor<fp32, [4096, 512]> model_encoder_layer_0_mlp_gated_layers_weight = const()[name = tensor<string, []>("model_encoder_layer_0_mlp_gated_layers_weight"), val = tensor<fp32, [4096, 512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(66732928)))];
            tensor<fp32, [512]> model_encoder_layer_0_mlp_wo_bias = const()[name = tensor<string, []>("model_encoder_layer_0_mlp_wo_bias"), val = tensor<fp32, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(75121600)))];
            tensor<fp32, [512, 2048]> model_encoder_layer_0_mlp_wo_weight = const()[name = tensor<string, []>("model_encoder_layer_0_mlp_wo_weight"), val = tensor<fp32, [512, 2048]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(75123712)))];
            tensor<fp32, [512]> model_encoder_layer_0_mlp_layernorm_bias = const()[name = tensor<string, []>("model_encoder_layer_0_mlp_layernorm_bias"), val = tensor<fp32, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(79318080)))];
            tensor<fp32, [512]> model_encoder_layer_0_mlp_layernorm_weight = const()[name = tensor<string, []>("model_encoder_layer_0_mlp_layernorm_weight"), val = tensor<fp32, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(79320192)))];
            tensor<fp32, [512]> model_encoder_layer_1_attention_self_query_bias = const()[name = tensor<string, []>("model_encoder_layer_1_attention_self_query_bias"), val = tensor<fp32, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(79322304)))];
            tensor<fp32, [512, 512]> model_encoder_layer_1_attention_self_query_weight = const()[name = tensor<string, []>("model_encoder_layer_1_attention_self_query_weight"), val = tensor<fp32, [512, 512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(79324416)))];
            tensor<fp32, [512]> model_encoder_layer_1_attention_self_key_bias = const()[name = tensor<string, []>("model_encoder_layer_1_attention_self_key_bias"), val = tensor<fp32, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(80373056)))];
            tensor<fp32, [512, 512]> model_encoder_layer_1_attention_self_key_weight = const()[name = tensor<string, []>("model_encoder_layer_1_attention_self_key_weight"), val = tensor<fp32, [512, 512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(80375168)))];
            tensor<fp32, [512]> model_encoder_layer_1_attention_self_value_bias = const()[name = tensor<string, []>("model_encoder_layer_1_attention_self_value_bias"), val = tensor<fp32, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(81423808)))];
            tensor<fp32, [512, 512]> model_encoder_layer_1_attention_self_value_weight = const()[name = tensor<string, []>("model_encoder_layer_1_attention_self_value_weight"), val = tensor<fp32, [512, 512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(81425920)))];
            tensor<fp32, [512]> model_encoder_layer_1_attention_output_dense_bias = const()[name = tensor<string, []>("model_encoder_layer_1_attention_output_dense_bias"), val = tensor<fp32, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(82474560)))];
            tensor<fp32, [512, 512]> model_encoder_layer_1_attention_output_dense_weight = const()[name = tensor<string, []>("model_encoder_layer_1_attention_output_dense_weight"), val = tensor<fp32, [512, 512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(82476672)))];
            tensor<fp32, [512]> model_encoder_layer_1_attention_output_LayerNorm_bias = const()[name = tensor<string, []>("model_encoder_layer_1_attention_output_LayerNorm_bias"), val = tensor<fp32, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(83525312)))];
            tensor<fp32, [512]> model_encoder_layer_1_attention_output_LayerNorm_weight = const()[name = tensor<string, []>("model_encoder_layer_1_attention_output_LayerNorm_weight"), val = tensor<fp32, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(83527424)))];
            tensor<fp32, [4096, 512]> model_encoder_layer_1_mlp_gated_layers_weight = const()[name = tensor<string, []>("model_encoder_layer_1_mlp_gated_layers_weight"), val = tensor<fp32, [4096, 512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(83529536)))];
            tensor<fp32, [512]> model_encoder_layer_1_mlp_wo_bias = const()[name = tensor<string, []>("model_encoder_layer_1_mlp_wo_bias"), val = tensor<fp32, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(91918208)))];
            tensor<fp32, [512, 2048]> model_encoder_layer_1_mlp_wo_weight = const()[name = tensor<string, []>("model_encoder_layer_1_mlp_wo_weight"), val = tensor<fp32, [512, 2048]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(91920320)))];
            tensor<fp32, [512]> model_encoder_layer_1_mlp_layernorm_bias = const()[name = tensor<string, []>("model_encoder_layer_1_mlp_layernorm_bias"), val = tensor<fp32, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(96114688)))];
            tensor<fp32, [512]> model_encoder_layer_1_mlp_layernorm_weight = const()[name = tensor<string, []>("model_encoder_layer_1_mlp_layernorm_weight"), val = tensor<fp32, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(96116800)))];
            tensor<fp32, [512]> model_encoder_layer_2_attention_self_query_bias = const()[name = tensor<string, []>("model_encoder_layer_2_attention_self_query_bias"), val = tensor<fp32, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(96118912)))];
            tensor<fp32, [512, 512]> model_encoder_layer_2_attention_self_query_weight = const()[name = tensor<string, []>("model_encoder_layer_2_attention_self_query_weight"), val = tensor<fp32, [512, 512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(96121024)))];
            tensor<fp32, [512]> model_encoder_layer_2_attention_self_key_bias = const()[name = tensor<string, []>("model_encoder_layer_2_attention_self_key_bias"), val = tensor<fp32, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(97169664)))];
            tensor<fp32, [512, 512]> model_encoder_layer_2_attention_self_key_weight = const()[name = tensor<string, []>("model_encoder_layer_2_attention_self_key_weight"), val = tensor<fp32, [512, 512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(97171776)))];
            tensor<fp32, [512]> model_encoder_layer_2_attention_self_value_bias = const()[name = tensor<string, []>("model_encoder_layer_2_attention_self_value_bias"), val = tensor<fp32, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(98220416)))];
            tensor<fp32, [512, 512]> model_encoder_layer_2_attention_self_value_weight = const()[name = tensor<string, []>("model_encoder_layer_2_attention_self_value_weight"), val = tensor<fp32, [512, 512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(98222528)))];
            tensor<fp32, [512]> model_encoder_layer_2_attention_output_dense_bias = const()[name = tensor<string, []>("model_encoder_layer_2_attention_output_dense_bias"), val = tensor<fp32, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(99271168)))];
            tensor<fp32, [512, 512]> model_encoder_layer_2_attention_output_dense_weight = const()[name = tensor<string, []>("model_encoder_layer_2_attention_output_dense_weight"), val = tensor<fp32, [512, 512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(99273280)))];
            tensor<fp32, [512]> model_encoder_layer_2_attention_output_LayerNorm_bias = const()[name = tensor<string, []>("model_encoder_layer_2_attention_output_LayerNorm_bias"), val = tensor<fp32, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(100321920)))];
            tensor<fp32, [512]> model_encoder_layer_2_attention_output_LayerNorm_weight = const()[name = tensor<string, []>("model_encoder_layer_2_attention_output_LayerNorm_weight"), val = tensor<fp32, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(100324032)))];
            tensor<fp32, [4096, 512]> model_encoder_layer_2_mlp_gated_layers_weight = const()[name = tensor<string, []>("model_encoder_layer_2_mlp_gated_layers_weight"), val = tensor<fp32, [4096, 512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(100326144)))];
            tensor<fp32, [512]> model_encoder_layer_2_mlp_wo_bias = const()[name = tensor<string, []>("model_encoder_layer_2_mlp_wo_bias"), val = tensor<fp32, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(108714816)))];
            tensor<fp32, [512, 2048]> model_encoder_layer_2_mlp_wo_weight = const()[name = tensor<string, []>("model_encoder_layer_2_mlp_wo_weight"), val = tensor<fp32, [512, 2048]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(108716928)))];
            tensor<fp32, [512]> model_encoder_layer_2_mlp_layernorm_bias = const()[name = tensor<string, []>("model_encoder_layer_2_mlp_layernorm_bias"), val = tensor<fp32, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(112911296)))];
            tensor<fp32, [512]> model_encoder_layer_2_mlp_layernorm_weight = const()[name = tensor<string, []>("model_encoder_layer_2_mlp_layernorm_weight"), val = tensor<fp32, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(112913408)))];
            tensor<fp32, [512]> model_encoder_layer_3_attention_self_query_bias = const()[name = tensor<string, []>("model_encoder_layer_3_attention_self_query_bias"), val = tensor<fp32, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(112915520)))];
            tensor<fp32, [512, 512]> model_encoder_layer_3_attention_self_query_weight = const()[name = tensor<string, []>("model_encoder_layer_3_attention_self_query_weight"), val = tensor<fp32, [512, 512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(112917632)))];
            tensor<fp32, [512]> model_encoder_layer_3_attention_self_key_bias = const()[name = tensor<string, []>("model_encoder_layer_3_attention_self_key_bias"), val = tensor<fp32, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(113966272)))];
            tensor<fp32, [512, 512]> model_encoder_layer_3_attention_self_key_weight = const()[name = tensor<string, []>("model_encoder_layer_3_attention_self_key_weight"), val = tensor<fp32, [512, 512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(113968384)))];
            tensor<fp32, [512]> model_encoder_layer_3_attention_self_value_bias = const()[name = tensor<string, []>("model_encoder_layer_3_attention_self_value_bias"), val = tensor<fp32, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(115017024)))];
            tensor<fp32, [512, 512]> model_encoder_layer_3_attention_self_value_weight = const()[name = tensor<string, []>("model_encoder_layer_3_attention_self_value_weight"), val = tensor<fp32, [512, 512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(115019136)))];
            tensor<fp32, [512]> model_encoder_layer_3_attention_output_dense_bias = const()[name = tensor<string, []>("model_encoder_layer_3_attention_output_dense_bias"), val = tensor<fp32, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(116067776)))];
            tensor<fp32, [512, 512]> model_encoder_layer_3_attention_output_dense_weight = const()[name = tensor<string, []>("model_encoder_layer_3_attention_output_dense_weight"), val = tensor<fp32, [512, 512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(116069888)))];
            tensor<fp32, [512]> model_encoder_layer_3_attention_output_LayerNorm_bias = const()[name = tensor<string, []>("model_encoder_layer_3_attention_output_LayerNorm_bias"), val = tensor<fp32, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(117118528)))];
            tensor<fp32, [512]> model_encoder_layer_3_attention_output_LayerNorm_weight = const()[name = tensor<string, []>("model_encoder_layer_3_attention_output_LayerNorm_weight"), val = tensor<fp32, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(117120640)))];
            tensor<fp32, [4096, 512]> model_encoder_layer_3_mlp_gated_layers_weight = const()[name = tensor<string, []>("model_encoder_layer_3_mlp_gated_layers_weight"), val = tensor<fp32, [4096, 512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(117122752)))];
            tensor<fp32, [512]> model_encoder_layer_3_mlp_wo_bias = const()[name = tensor<string, []>("model_encoder_layer_3_mlp_wo_bias"), val = tensor<fp32, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(125511424)))];
            tensor<fp32, [512, 2048]> model_encoder_layer_3_mlp_wo_weight = const()[name = tensor<string, []>("model_encoder_layer_3_mlp_wo_weight"), val = tensor<fp32, [512, 2048]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(125513536)))];
            tensor<fp32, [512]> model_encoder_layer_3_mlp_layernorm_bias = const()[name = tensor<string, []>("model_encoder_layer_3_mlp_layernorm_bias"), val = tensor<fp32, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(129707904)))];
            tensor<fp32, [512]> model_encoder_layer_3_mlp_layernorm_weight = const()[name = tensor<string, []>("model_encoder_layer_3_mlp_layernorm_weight"), val = tensor<fp32, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(129710016)))];
            tensor<fp32, [512]> model_pooler_dense_bias = const()[name = tensor<string, []>("model_pooler_dense_bias"), val = tensor<fp32, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(129712128)))];
            tensor<fp32, [512, 512]> model_pooler_dense_weight = const()[name = tensor<string, []>("model_pooler_dense_weight"), val = tensor<fp32, [512, 512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(129714240)))];
            tensor<int32, []> var_10 = const()[name = tensor<string, []>("op_10"), val = tensor<int32, []>(-1)];
            tensor<fp32, []> var_12 = const()[name = tensor<string, []>("op_12"), val = tensor<fp32, []>(0x1.197998p-40)];
            tensor<fp32, []> var_15 = const()[name = tensor<string, []>("op_15"), val = tensor<fp32, []>(0x1p+0)];
            tensor<int32, [1]> var_36_axes_0 = const()[name = tensor<string, []>("op_36_axes_0"), val = tensor<int32, [1]>([1])];
            tensor<int32, [1, 1, 128]> var_36 = expand_dims(axes = var_36_axes_0, x = attention_mask)[name = tensor<string, []>("op_36")];
            tensor<int32, [1]> var_37_axes_0 = const()[name = tensor<string, []>("op_37_axes_0"), val = tensor<int32, [1]>([2])];
            tensor<int32, [1, 1, 1, 128]> var_37 = expand_dims(axes = var_37_axes_0, x = var_36)[name = tensor<string, []>("op_37")];
            tensor<string, []> var_39_dtype_0 = const()[name = tensor<string, []>("op_39_dtype_0"), val = tensor<string, []>("fp32")];
            tensor<fp32, [1, 1, 1, 128]> cast_26 = cast(dtype = var_39_dtype_0, x = var_37)[name = tensor<string, []>("cast_26")];
            tensor<fp32, [1, 1, 1, 128]> var_40 = sub(x = var_15, y = cast_26)[name = tensor<string, []>("op_40")];
            tensor<fp32, []> var_41 = const()[name = tensor<string, []>("op_41"), val = tensor<fp32, []>(-0x1.fffffep+127)];
            tensor<fp32, [1, 1, 1, 128]> attention_mask_1 = mul(x = var_40, y = var_41)[name = tensor<string, []>("attention_mask")];
            tensor<int32, []> inputs_embeds_axis_0 = const()[name = tensor<string, []>("inputs_embeds_axis_0"), val = tensor<int32, []>(0)];
            tensor<fp32, [1, 128, 512]> inputs_embeds = gather(axis = inputs_embeds_axis_0, indices = input_ids, x = model_embeddings_word_embeddings_weight)[name = tensor<string, []>("inputs_embeds")];
            tensor<fp32, [1, 128, 512]> token_type_embeddings_1 = const()[name = tensor<string, []>("token_type_embeddings_1"), val = tensor<fp32, [1, 128, 512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(130762880)))];
            tensor<fp32, [1, 128, 512]> input_3 = add(x = inputs_embeds, y = token_type_embeddings_1)[name = tensor<string, []>("input_3")];
            tensor<int32, [1]> input_5_axes_0 = const()[name = tensor<string, []>("input_5_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp32, [1, 128, 512]> input_5 = layer_norm(axes = input_5_axes_0, beta = model_embeddings_LayerNorm_bias, epsilon = var_12, gamma = model_embeddings_LayerNorm_weight, x = input_3)[name = tensor<string, []>("input_5")];
            tensor<fp32, [1, 8, 128, 128]> bias_3 = const()[name = tensor<string, []>("bias_3"), val = tensor<fp32, [1, 8, 128, 128]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(131025088)))];
            tensor<fp32, [1, 128, 512]> linear_0 = linear(bias = model_encoder_layer_0_attention_self_query_bias, weight = model_encoder_layer_0_attention_self_query_weight, x = input_5)[name = tensor<string, []>("linear_0")];
            tensor<fp32, [1, 128, 512]> linear_1 = linear(bias = model_encoder_layer_0_attention_self_key_bias, weight = model_encoder_layer_0_attention_self_key_weight, x = input_5)[name = tensor<string, []>("linear_1")];
            tensor<int32, [4]> var_85 = const()[name = tensor<string, []>("op_85"), val = tensor<int32, [4]>([1, 128, 8, 64])];
            tensor<fp32, [1, 128, 8, 64]> x_3 = reshape(shape = var_85, x = linear_1)[name = tensor<string, []>("x_3")];
            tensor<fp32, [1, 128, 512]> linear_2 = linear(bias = model_encoder_layer_0_attention_self_value_bias, weight = model_encoder_layer_0_attention_self_value_weight, x = input_5)[name = tensor<string, []>("linear_2")];
            tensor<int32, [4]> var_94 = const()[name = tensor<string, []>("op_94"), val = tensor<int32, [4]>([1, 128, 8, 64])];
            tensor<fp32, [1, 128, 8, 64]> x_7 = reshape(shape = var_94, x = linear_2)[name = tensor<string, []>("x_7")];
            tensor<int32, [4]> var_96 = const()[name = tensor<string, []>("op_96"), val = tensor<int32, [4]>([0, 2, 1, 3])];
            tensor<int32, [4]> var_100 = const()[name = tensor<string, []>("op_100"), val = tensor<int32, [4]>([1, 128, 8, 64])];
            tensor<fp32, [1, 128, 8, 64]> x_11 = reshape(shape = var_100, x = linear_0)[name = tensor<string, []>("x_11")];
            tensor<bool, []> attention_scores_1_transpose_x_0 = const()[name = tensor<string, []>("attention_scores_1_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<bool, []> attention_scores_1_transpose_y_0 = const()[name = tensor<string, []>("attention_scores_1_transpose_y_0"), val = tensor<bool, []>(false)];
            tensor<int32, [4]> transpose_12_perm_0 = const()[name = tensor<string, []>("transpose_12_perm_0"), val = tensor<int32, [4]>([0, 2, 1, 3])];
            tensor<int32, [4]> transpose_13_perm_0 = const()[name = tensor<string, []>("transpose_13_perm_0"), val = tensor<int32, [4]>([0, 2, 3, 1])];
            tensor<fp32, [1, 8, 64, 128]> transpose_33 = transpose(perm = transpose_13_perm_0, x = x_3)[name = tensor<string, []>("transpose_33")];
            tensor<fp32, [1, 8, 128, 64]> transpose_34 = transpose(perm = transpose_12_perm_0, x = x_11)[name = tensor<string, []>("transpose_34")];
            tensor<fp32, [1, 8, 128, 128]> attention_scores_1 = matmul(transpose_x = attention_scores_1_transpose_x_0, transpose_y = attention_scores_1_transpose_y_0, x = transpose_34, y = transpose_33)[name = tensor<string, []>("attention_scores_1")];
            tensor<fp32, []> _inversed_attention_scores_3_y_0 = const()[name = tensor<string, []>("_inversed_attention_scores_3_y_0"), val = tensor<fp32, []>(0x1p-3)];
            tensor<fp32, [1, 8, 128, 128]> _inversed_attention_scores_3 = mul(x = attention_scores_1, y = _inversed_attention_scores_3_y_0)[name = tensor<string, []>("_inversed_attention_scores_3")];
            tensor<fp32, [1, 8, 128, 128]> attention_scores_5 = add(x = _inversed_attention_scores_3, y = attention_mask_1)[name = tensor<string, []>("attention_scores_5")];
            tensor<fp32, [1, 8, 128, 128]> input_7 = add(x = attention_scores_5, y = bias_3)[name = tensor<string, []>("input_7")];
            tensor<fp32, [1, 8, 128, 128]> input_9 = softmax(axis = var_10, x = input_7)[name = tensor<string, []>("input_9")];
            tensor<bool, []> context_layer_1_transpose_x_0 = const()[name = tensor<string, []>("context_layer_1_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<bool, []> context_layer_1_transpose_y_0 = const()[name = tensor<string, []>("context_layer_1_transpose_y_0"), val = tensor<bool, []>(false)];
            tensor<fp32, [1, 8, 128, 64]> transpose_35 = transpose(perm = var_96, x = x_7)[name = tensor<string, []>("transpose_35")];
            tensor<fp32, [1, 8, 128, 64]> context_layer_1 = matmul(transpose_x = context_layer_1_transpose_x_0, transpose_y = context_layer_1_transpose_y_0, x = input_9, y = transpose_35)[name = tensor<string, []>("context_layer_1")];
            tensor<int32, [4]> var_113 = const()[name = tensor<string, []>("op_113"), val = tensor<int32, [4]>([0, 2, 1, 3])];
            tensor<int32, [3]> var_118 = const()[name = tensor<string, []>("op_118"), val = tensor<int32, [3]>([1, 128, 512])];
            tensor<fp32, [1, 128, 8, 64]> transpose_32 = transpose(perm = var_113, x = context_layer_1)[name = tensor<string, []>("transpose_32")];
            tensor<fp32, [1, 128, 512]> input_11 = reshape(shape = var_118, x = transpose_32)[name = tensor<string, []>("input_11")];
            tensor<fp32, [1, 128, 512]> linear_3 = linear(bias = model_encoder_layer_0_attention_output_dense_bias, weight = model_encoder_layer_0_attention_output_dense_weight, x = input_11)[name = tensor<string, []>("linear_3")];
            tensor<fp32, [1, 128, 512]> input_15 = add(x = linear_3, y = input_5)[name = tensor<string, []>("input_15")];
            tensor<int32, [1]> input_17_axes_0 = const()[name = tensor<string, []>("input_17_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp32, [1, 128, 512]> input_17 = layer_norm(axes = input_17_axes_0, beta = model_encoder_layer_0_attention_output_LayerNorm_bias, epsilon = var_12, gamma = model_encoder_layer_0_attention_output_LayerNorm_weight, x = input_15)[name = tensor<string, []>("input_17")];
            tensor<fp32, [4096]> linear_4_bias_0 = const()[name = tensor<string, []>("linear_4_bias_0"), val = tensor<fp32, [4096]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(131549440)))];
            tensor<fp32, [1, 128, 4096]> linear_4 = linear(bias = linear_4_bias_0, weight = model_encoder_layer_0_mlp_gated_layers_weight, x = input_17)[name = tensor<string, []>("linear_4")];
            tensor<int32, [3]> input_19_begin_0 = const()[name = tensor<string, []>("input_19_begin_0"), val = tensor<int32, [3]>([0, 0, 0])];
            tensor<int32, [3]> input_19_end_0 = const()[name = tensor<string, []>("input_19_end_0"), val = tensor<int32, [3]>([1, 128, 2048])];
            tensor<bool, [3]> input_19_end_mask_0 = const()[name = tensor<string, []>("input_19_end_mask_0"), val = tensor<bool, [3]>([true, true, false])];
            tensor<fp32, [1, 128, 2048]> input_19 = slice_by_index(begin = input_19_begin_0, end = input_19_end_0, end_mask = input_19_end_mask_0, x = linear_4)[name = tensor<string, []>("input_19")];
            tensor<int32, [3]> non_gated_1_begin_0 = const()[name = tensor<string, []>("non_gated_1_begin_0"), val = tensor<int32, [3]>([0, 0, 2048])];
            tensor<int32, [3]> non_gated_1_end_0 = const()[name = tensor<string, []>("non_gated_1_end_0"), val = tensor<int32, [3]>([1, 128, 4096])];
            tensor<bool, [3]> non_gated_1_end_mask_0 = const()[name = tensor<string, []>("non_gated_1_end_mask_0"), val = tensor<bool, [3]>([true, true, true])];
            tensor<fp32, [1, 128, 2048]> non_gated_1 = slice_by_index(begin = non_gated_1_begin_0, end = non_gated_1_end_0, end_mask = non_gated_1_end_mask_0, x = linear_4)[name = tensor<string, []>("non_gated_1")];
            tensor<string, []> var_142_mode_0 = const()[name = tensor<string, []>("op_142_mode_0"), val = tensor<string, []>("EXACT")];
            tensor<fp32, [1, 128, 2048]> var_142 = gelu(mode = var_142_mode_0, x = input_19)[name = tensor<string, []>("op_142")];
            tensor<fp32, [1, 128, 2048]> input_21 = mul(x = var_142, y = non_gated_1)[name = tensor<string, []>("input_21")];
            tensor<fp32, [1, 128, 512]> linear_5 = linear(bias = model_encoder_layer_0_mlp_wo_bias, weight = model_encoder_layer_0_mlp_wo_weight, x = input_21)[name = tensor<string, []>("linear_5")];
            tensor<fp32, [1, 128, 512]> input_25 = add(x = linear_5, y = input_17)[name = tensor<string, []>("input_25")];
            tensor<int32, [1]> input_27_axes_0 = const()[name = tensor<string, []>("input_27_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp32, [1, 128, 512]> input_27 = layer_norm(axes = input_27_axes_0, beta = model_encoder_layer_0_mlp_layernorm_bias, epsilon = var_12, gamma = model_encoder_layer_0_mlp_layernorm_weight, x = input_25)[name = tensor<string, []>("input_27")];
            tensor<fp32, [1, 128, 512]> linear_6 = linear(bias = model_encoder_layer_1_attention_self_query_bias, weight = model_encoder_layer_1_attention_self_query_weight, x = input_27)[name = tensor<string, []>("linear_6")];
            tensor<fp32, [1, 128, 512]> linear_7 = linear(bias = model_encoder_layer_1_attention_self_key_bias, weight = model_encoder_layer_1_attention_self_key_weight, x = input_27)[name = tensor<string, []>("linear_7")];
            tensor<int32, [4]> var_168 = const()[name = tensor<string, []>("op_168"), val = tensor<int32, [4]>([1, 128, 8, 64])];
            tensor<fp32, [1, 128, 8, 64]> x_15 = reshape(shape = var_168, x = linear_7)[name = tensor<string, []>("x_15")];
            tensor<fp32, [1, 128, 512]> linear_8 = linear(bias = model_encoder_layer_1_attention_self_value_bias, weight = model_encoder_layer_1_attention_self_value_weight, x = input_27)[name = tensor<string, []>("linear_8")];
            tensor<int32, [4]> var_177 = const()[name = tensor<string, []>("op_177"), val = tensor<int32, [4]>([1, 128, 8, 64])];
            tensor<fp32, [1, 128, 8, 64]> x_19 = reshape(shape = var_177, x = linear_8)[name = tensor<string, []>("x_19")];
            tensor<int32, [4]> var_179 = const()[name = tensor<string, []>("op_179"), val = tensor<int32, [4]>([0, 2, 1, 3])];
            tensor<int32, [4]> var_183 = const()[name = tensor<string, []>("op_183"), val = tensor<int32, [4]>([1, 128, 8, 64])];
            tensor<fp32, [1, 128, 8, 64]> x_23 = reshape(shape = var_183, x = linear_6)[name = tensor<string, []>("x_23")];
            tensor<bool, []> attention_scores_7_transpose_x_0 = const()[name = tensor<string, []>("attention_scores_7_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<bool, []> attention_scores_7_transpose_y_0 = const()[name = tensor<string, []>("attention_scores_7_transpose_y_0"), val = tensor<bool, []>(false)];
            tensor<int32, [4]> transpose_14_perm_0 = const()[name = tensor<string, []>("transpose_14_perm_0"), val = tensor<int32, [4]>([0, 2, 1, 3])];
            tensor<int32, [4]> transpose_15_perm_0 = const()[name = tensor<string, []>("transpose_15_perm_0"), val = tensor<int32, [4]>([0, 2, 3, 1])];
            tensor<fp32, [1, 8, 64, 128]> transpose_29 = transpose(perm = transpose_15_perm_0, x = x_15)[name = tensor<string, []>("transpose_29")];
            tensor<fp32, [1, 8, 128, 64]> transpose_30 = transpose(perm = transpose_14_perm_0, x = x_23)[name = tensor<string, []>("transpose_30")];
            tensor<fp32, [1, 8, 128, 128]> attention_scores_7 = matmul(transpose_x = attention_scores_7_transpose_x_0, transpose_y = attention_scores_7_transpose_y_0, x = transpose_30, y = transpose_29)[name = tensor<string, []>("attention_scores_7")];
            tensor<fp32, []> _inversed_attention_scores_9_y_0 = const()[name = tensor<string, []>("_inversed_attention_scores_9_y_0"), val = tensor<fp32, []>(0x1p-3)];
            tensor<fp32, [1, 8, 128, 128]> _inversed_attention_scores_9 = mul(x = attention_scores_7, y = _inversed_attention_scores_9_y_0)[name = tensor<string, []>("_inversed_attention_scores_9")];
            tensor<fp32, [1, 8, 128, 128]> attention_scores_11 = add(x = _inversed_attention_scores_9, y = attention_mask_1)[name = tensor<string, []>("attention_scores_11")];
            tensor<fp32, [1, 8, 128, 128]> input_29 = add(x = attention_scores_11, y = bias_3)[name = tensor<string, []>("input_29")];
            tensor<fp32, [1, 8, 128, 128]> input_31 = softmax(axis = var_10, x = input_29)[name = tensor<string, []>("input_31")];
            tensor<bool, []> context_layer_5_transpose_x_0 = const()[name = tensor<string, []>("context_layer_5_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<bool, []> context_layer_5_transpose_y_0 = const()[name = tensor<string, []>("context_layer_5_transpose_y_0"), val = tensor<bool, []>(false)];
            tensor<fp32, [1, 8, 128, 64]> transpose_31 = transpose(perm = var_179, x = x_19)[name = tensor<string, []>("transpose_31")];
            tensor<fp32, [1, 8, 128, 64]> context_layer_5 = matmul(transpose_x = context_layer_5_transpose_x_0, transpose_y = context_layer_5_transpose_y_0, x = input_31, y = transpose_31)[name = tensor<string, []>("context_layer_5")];
            tensor<int32, [4]> var_196 = const()[name = tensor<string, []>("op_196"), val = tensor<int32, [4]>([0, 2, 1, 3])];
            tensor<int32, [3]> var_201 = const()[name = tensor<string, []>("op_201"), val = tensor<int32, [3]>([1, 128, 512])];
            tensor<fp32, [1, 128, 8, 64]> transpose_28 = transpose(perm = var_196, x = context_layer_5)[name = tensor<string, []>("transpose_28")];
            tensor<fp32, [1, 128, 512]> input_33 = reshape(shape = var_201, x = transpose_28)[name = tensor<string, []>("input_33")];
            tensor<fp32, [1, 128, 512]> linear_9 = linear(bias = model_encoder_layer_1_attention_output_dense_bias, weight = model_encoder_layer_1_attention_output_dense_weight, x = input_33)[name = tensor<string, []>("linear_9")];
            tensor<fp32, [1, 128, 512]> input_37 = add(x = linear_9, y = input_27)[name = tensor<string, []>("input_37")];
            tensor<int32, [1]> input_39_axes_0 = const()[name = tensor<string, []>("input_39_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp32, [1, 128, 512]> input_39 = layer_norm(axes = input_39_axes_0, beta = model_encoder_layer_1_attention_output_LayerNorm_bias, epsilon = var_12, gamma = model_encoder_layer_1_attention_output_LayerNorm_weight, x = input_37)[name = tensor<string, []>("input_39")];
            tensor<fp32, [1, 128, 4096]> linear_10 = linear(bias = linear_4_bias_0, weight = model_encoder_layer_1_mlp_gated_layers_weight, x = input_39)[name = tensor<string, []>("linear_10")];
            tensor<int32, [3]> input_41_begin_0 = const()[name = tensor<string, []>("input_41_begin_0"), val = tensor<int32, [3]>([0, 0, 0])];
            tensor<int32, [3]> input_41_end_0 = const()[name = tensor<string, []>("input_41_end_0"), val = tensor<int32, [3]>([1, 128, 2048])];
            tensor<bool, [3]> input_41_end_mask_0 = const()[name = tensor<string, []>("input_41_end_mask_0"), val = tensor<bool, [3]>([true, true, false])];
            tensor<fp32, [1, 128, 2048]> input_41 = slice_by_index(begin = input_41_begin_0, end = input_41_end_0, end_mask = input_41_end_mask_0, x = linear_10)[name = tensor<string, []>("input_41")];
            tensor<int32, [3]> non_gated_3_begin_0 = const()[name = tensor<string, []>("non_gated_3_begin_0"), val = tensor<int32, [3]>([0, 0, 2048])];
            tensor<int32, [3]> non_gated_3_end_0 = const()[name = tensor<string, []>("non_gated_3_end_0"), val = tensor<int32, [3]>([1, 128, 4096])];
            tensor<bool, [3]> non_gated_3_end_mask_0 = const()[name = tensor<string, []>("non_gated_3_end_mask_0"), val = tensor<bool, [3]>([true, true, true])];
            tensor<fp32, [1, 128, 2048]> non_gated_3 = slice_by_index(begin = non_gated_3_begin_0, end = non_gated_3_end_0, end_mask = non_gated_3_end_mask_0, x = linear_10)[name = tensor<string, []>("non_gated_3")];
            tensor<string, []> var_225_mode_0 = const()[name = tensor<string, []>("op_225_mode_0"), val = tensor<string, []>("EXACT")];
            tensor<fp32, [1, 128, 2048]> var_225 = gelu(mode = var_225_mode_0, x = input_41)[name = tensor<string, []>("op_225")];
            tensor<fp32, [1, 128, 2048]> input_43 = mul(x = var_225, y = non_gated_3)[name = tensor<string, []>("input_43")];
            tensor<fp32, [1, 128, 512]> linear_11 = linear(bias = model_encoder_layer_1_mlp_wo_bias, weight = model_encoder_layer_1_mlp_wo_weight, x = input_43)[name = tensor<string, []>("linear_11")];
            tensor<fp32, [1, 128, 512]> input_47 = add(x = linear_11, y = input_39)[name = tensor<string, []>("input_47")];
            tensor<int32, [1]> input_49_axes_0 = const()[name = tensor<string, []>("input_49_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp32, [1, 128, 512]> input_49 = layer_norm(axes = input_49_axes_0, beta = model_encoder_layer_1_mlp_layernorm_bias, epsilon = var_12, gamma = model_encoder_layer_1_mlp_layernorm_weight, x = input_47)[name = tensor<string, []>("input_49")];
            tensor<fp32, [1, 128, 512]> linear_12 = linear(bias = model_encoder_layer_2_attention_self_query_bias, weight = model_encoder_layer_2_attention_self_query_weight, x = input_49)[name = tensor<string, []>("linear_12")];
            tensor<fp32, [1, 128, 512]> linear_13 = linear(bias = model_encoder_layer_2_attention_self_key_bias, weight = model_encoder_layer_2_attention_self_key_weight, x = input_49)[name = tensor<string, []>("linear_13")];
            tensor<int32, [4]> var_251 = const()[name = tensor<string, []>("op_251"), val = tensor<int32, [4]>([1, 128, 8, 64])];
            tensor<fp32, [1, 128, 8, 64]> x_27 = reshape(shape = var_251, x = linear_13)[name = tensor<string, []>("x_27")];
            tensor<fp32, [1, 128, 512]> linear_14 = linear(bias = model_encoder_layer_2_attention_self_value_bias, weight = model_encoder_layer_2_attention_self_value_weight, x = input_49)[name = tensor<string, []>("linear_14")];
            tensor<int32, [4]> var_260 = const()[name = tensor<string, []>("op_260"), val = tensor<int32, [4]>([1, 128, 8, 64])];
            tensor<fp32, [1, 128, 8, 64]> x_31 = reshape(shape = var_260, x = linear_14)[name = tensor<string, []>("x_31")];
            tensor<int32, [4]> var_262 = const()[name = tensor<string, []>("op_262"), val = tensor<int32, [4]>([0, 2, 1, 3])];
            tensor<int32, [4]> var_266 = const()[name = tensor<string, []>("op_266"), val = tensor<int32, [4]>([1, 128, 8, 64])];
            tensor<fp32, [1, 128, 8, 64]> x_35 = reshape(shape = var_266, x = linear_12)[name = tensor<string, []>("x_35")];
            tensor<bool, []> attention_scores_13_transpose_x_0 = const()[name = tensor<string, []>("attention_scores_13_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<bool, []> attention_scores_13_transpose_y_0 = const()[name = tensor<string, []>("attention_scores_13_transpose_y_0"), val = tensor<bool, []>(false)];
            tensor<int32, [4]> transpose_16_perm_0 = const()[name = tensor<string, []>("transpose_16_perm_0"), val = tensor<int32, [4]>([0, 2, 1, 3])];
            tensor<int32, [4]> transpose_17_perm_0 = const()[name = tensor<string, []>("transpose_17_perm_0"), val = tensor<int32, [4]>([0, 2, 3, 1])];
            tensor<fp32, [1, 8, 64, 128]> transpose_25 = transpose(perm = transpose_17_perm_0, x = x_27)[name = tensor<string, []>("transpose_25")];
            tensor<fp32, [1, 8, 128, 64]> transpose_26 = transpose(perm = transpose_16_perm_0, x = x_35)[name = tensor<string, []>("transpose_26")];
            tensor<fp32, [1, 8, 128, 128]> attention_scores_13 = matmul(transpose_x = attention_scores_13_transpose_x_0, transpose_y = attention_scores_13_transpose_y_0, x = transpose_26, y = transpose_25)[name = tensor<string, []>("attention_scores_13")];
            tensor<fp32, []> _inversed_attention_scores_15_y_0 = const()[name = tensor<string, []>("_inversed_attention_scores_15_y_0"), val = tensor<fp32, []>(0x1p-3)];
            tensor<fp32, [1, 8, 128, 128]> _inversed_attention_scores_15 = mul(x = attention_scores_13, y = _inversed_attention_scores_15_y_0)[name = tensor<string, []>("_inversed_attention_scores_15")];
            tensor<fp32, [1, 8, 128, 128]> attention_scores_17 = add(x = _inversed_attention_scores_15, y = attention_mask_1)[name = tensor<string, []>("attention_scores_17")];
            tensor<fp32, [1, 8, 128, 128]> input_51 = add(x = attention_scores_17, y = bias_3)[name = tensor<string, []>("input_51")];
            tensor<fp32, [1, 8, 128, 128]> input_53 = softmax(axis = var_10, x = input_51)[name = tensor<string, []>("input_53")];
            tensor<bool, []> context_layer_9_transpose_x_0 = const()[name = tensor<string, []>("context_layer_9_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<bool, []> context_layer_9_transpose_y_0 = const()[name = tensor<string, []>("context_layer_9_transpose_y_0"), val = tensor<bool, []>(false)];
            tensor<fp32, [1, 8, 128, 64]> transpose_27 = transpose(perm = var_262, x = x_31)[name = tensor<string, []>("transpose_27")];
            tensor<fp32, [1, 8, 128, 64]> context_layer_9 = matmul(transpose_x = context_layer_9_transpose_x_0, transpose_y = context_layer_9_transpose_y_0, x = input_53, y = transpose_27)[name = tensor<string, []>("context_layer_9")];
            tensor<int32, [4]> var_279 = const()[name = tensor<string, []>("op_279"), val = tensor<int32, [4]>([0, 2, 1, 3])];
            tensor<int32, [3]> var_284 = const()[name = tensor<string, []>("op_284"), val = tensor<int32, [3]>([1, 128, 512])];
            tensor<fp32, [1, 128, 8, 64]> transpose_24 = transpose(perm = var_279, x = context_layer_9)[name = tensor<string, []>("transpose_24")];
            tensor<fp32, [1, 128, 512]> input_55 = reshape(shape = var_284, x = transpose_24)[name = tensor<string, []>("input_55")];
            tensor<fp32, [1, 128, 512]> linear_15 = linear(bias = model_encoder_layer_2_attention_output_dense_bias, weight = model_encoder_layer_2_attention_output_dense_weight, x = input_55)[name = tensor<string, []>("linear_15")];
            tensor<fp32, [1, 128, 512]> input_59 = add(x = linear_15, y = input_49)[name = tensor<string, []>("input_59")];
            tensor<int32, [1]> input_61_axes_0 = const()[name = tensor<string, []>("input_61_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp32, [1, 128, 512]> input_61 = layer_norm(axes = input_61_axes_0, beta = model_encoder_layer_2_attention_output_LayerNorm_bias, epsilon = var_12, gamma = model_encoder_layer_2_attention_output_LayerNorm_weight, x = input_59)[name = tensor<string, []>("input_61")];
            tensor<fp32, [1, 128, 4096]> linear_16 = linear(bias = linear_4_bias_0, weight = model_encoder_layer_2_mlp_gated_layers_weight, x = input_61)[name = tensor<string, []>("linear_16")];
            tensor<int32, [3]> input_63_begin_0 = const()[name = tensor<string, []>("input_63_begin_0"), val = tensor<int32, [3]>([0, 0, 0])];
            tensor<int32, [3]> input_63_end_0 = const()[name = tensor<string, []>("input_63_end_0"), val = tensor<int32, [3]>([1, 128, 2048])];
            tensor<bool, [3]> input_63_end_mask_0 = const()[name = tensor<string, []>("input_63_end_mask_0"), val = tensor<bool, [3]>([true, true, false])];
            tensor<fp32, [1, 128, 2048]> input_63 = slice_by_index(begin = input_63_begin_0, end = input_63_end_0, end_mask = input_63_end_mask_0, x = linear_16)[name = tensor<string, []>("input_63")];
            tensor<int32, [3]> non_gated_5_begin_0 = const()[name = tensor<string, []>("non_gated_5_begin_0"), val = tensor<int32, [3]>([0, 0, 2048])];
            tensor<int32, [3]> non_gated_5_end_0 = const()[name = tensor<string, []>("non_gated_5_end_0"), val = tensor<int32, [3]>([1, 128, 4096])];
            tensor<bool, [3]> non_gated_5_end_mask_0 = const()[name = tensor<string, []>("non_gated_5_end_mask_0"), val = tensor<bool, [3]>([true, true, true])];
            tensor<fp32, [1, 128, 2048]> non_gated_5 = slice_by_index(begin = non_gated_5_begin_0, end = non_gated_5_end_0, end_mask = non_gated_5_end_mask_0, x = linear_16)[name = tensor<string, []>("non_gated_5")];
            tensor<string, []> var_308_mode_0 = const()[name = tensor<string, []>("op_308_mode_0"), val = tensor<string, []>("EXACT")];
            tensor<fp32, [1, 128, 2048]> var_308 = gelu(mode = var_308_mode_0, x = input_63)[name = tensor<string, []>("op_308")];
            tensor<fp32, [1, 128, 2048]> input_65 = mul(x = var_308, y = non_gated_5)[name = tensor<string, []>("input_65")];
            tensor<fp32, [1, 128, 512]> linear_17 = linear(bias = model_encoder_layer_2_mlp_wo_bias, weight = model_encoder_layer_2_mlp_wo_weight, x = input_65)[name = tensor<string, []>("linear_17")];
            tensor<fp32, [1, 128, 512]> input_69 = add(x = linear_17, y = input_61)[name = tensor<string, []>("input_69")];
            tensor<int32, [1]> input_71_axes_0 = const()[name = tensor<string, []>("input_71_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp32, [1, 128, 512]> input_71 = layer_norm(axes = input_71_axes_0, beta = model_encoder_layer_2_mlp_layernorm_bias, epsilon = var_12, gamma = model_encoder_layer_2_mlp_layernorm_weight, x = input_69)[name = tensor<string, []>("input_71")];
            tensor<fp32, [1, 128, 512]> linear_18 = linear(bias = model_encoder_layer_3_attention_self_query_bias, weight = model_encoder_layer_3_attention_self_query_weight, x = input_71)[name = tensor<string, []>("linear_18")];
            tensor<fp32, [1, 128, 512]> linear_19 = linear(bias = model_encoder_layer_3_attention_self_key_bias, weight = model_encoder_layer_3_attention_self_key_weight, x = input_71)[name = tensor<string, []>("linear_19")];
            tensor<int32, [4]> var_334 = const()[name = tensor<string, []>("op_334"), val = tensor<int32, [4]>([1, 128, 8, 64])];
            tensor<fp32, [1, 128, 8, 64]> x_39 = reshape(shape = var_334, x = linear_19)[name = tensor<string, []>("x_39")];
            tensor<fp32, [1, 128, 512]> linear_20 = linear(bias = model_encoder_layer_3_attention_self_value_bias, weight = model_encoder_layer_3_attention_self_value_weight, x = input_71)[name = tensor<string, []>("linear_20")];
            tensor<int32, [4]> var_343 = const()[name = tensor<string, []>("op_343"), val = tensor<int32, [4]>([1, 128, 8, 64])];
            tensor<fp32, [1, 128, 8, 64]> x_43 = reshape(shape = var_343, x = linear_20)[name = tensor<string, []>("x_43")];
            tensor<int32, [4]> var_345 = const()[name = tensor<string, []>("op_345"), val = tensor<int32, [4]>([0, 2, 1, 3])];
            tensor<int32, [4]> var_349 = const()[name = tensor<string, []>("op_349"), val = tensor<int32, [4]>([1, 128, 8, 64])];
            tensor<fp32, [1, 128, 8, 64]> x = reshape(shape = var_349, x = linear_18)[name = tensor<string, []>("x")];
            tensor<bool, []> attention_scores_19_transpose_x_0 = const()[name = tensor<string, []>("attention_scores_19_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<bool, []> attention_scores_19_transpose_y_0 = const()[name = tensor<string, []>("attention_scores_19_transpose_y_0"), val = tensor<bool, []>(false)];
            tensor<int32, [4]> transpose_18_perm_0 = const()[name = tensor<string, []>("transpose_18_perm_0"), val = tensor<int32, [4]>([0, 2, 1, 3])];
            tensor<int32, [4]> transpose_19_perm_0 = const()[name = tensor<string, []>("transpose_19_perm_0"), val = tensor<int32, [4]>([0, 2, 3, 1])];
            tensor<fp32, [1, 8, 64, 128]> transpose_21 = transpose(perm = transpose_19_perm_0, x = x_39)[name = tensor<string, []>("transpose_21")];
            tensor<fp32, [1, 8, 128, 64]> transpose_22 = transpose(perm = transpose_18_perm_0, x = x)[name = tensor<string, []>("transpose_22")];
            tensor<fp32, [1, 8, 128, 128]> attention_scores_19 = matmul(transpose_x = attention_scores_19_transpose_x_0, transpose_y = attention_scores_19_transpose_y_0, x = transpose_22, y = transpose_21)[name = tensor<string, []>("attention_scores_19")];
            tensor<fp32, []> _inversed_attention_scores_21_y_0 = const()[name = tensor<string, []>("_inversed_attention_scores_21_y_0"), val = tensor<fp32, []>(0x1p-3)];
            tensor<fp32, [1, 8, 128, 128]> _inversed_attention_scores_21 = mul(x = attention_scores_19, y = _inversed_attention_scores_21_y_0)[name = tensor<string, []>("_inversed_attention_scores_21")];
            tensor<fp32, [1, 8, 128, 128]> attention_scores = add(x = _inversed_attention_scores_21, y = attention_mask_1)[name = tensor<string, []>("attention_scores")];
            tensor<fp32, [1, 8, 128, 128]> input_73 = add(x = attention_scores, y = bias_3)[name = tensor<string, []>("input_73")];
            tensor<fp32, [1, 8, 128, 128]> input_75 = softmax(axis = var_10, x = input_73)[name = tensor<string, []>("input_75")];
            tensor<bool, []> context_layer_13_transpose_x_0 = const()[name = tensor<string, []>("context_layer_13_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<bool, []> context_layer_13_transpose_y_0 = const()[name = tensor<string, []>("context_layer_13_transpose_y_0"), val = tensor<bool, []>(false)];
            tensor<fp32, [1, 8, 128, 64]> transpose_23 = transpose(perm = var_345, x = x_43)[name = tensor<string, []>("transpose_23")];
            tensor<fp32, [1, 8, 128, 64]> context_layer_13 = matmul(transpose_x = context_layer_13_transpose_x_0, transpose_y = context_layer_13_transpose_y_0, x = input_75, y = transpose_23)[name = tensor<string, []>("context_layer_13")];
            tensor<int32, [4]> var_362 = const()[name = tensor<string, []>("op_362"), val = tensor<int32, [4]>([0, 2, 1, 3])];
            tensor<int32, [3]> var_367 = const()[name = tensor<string, []>("op_367"), val = tensor<int32, [3]>([1, 128, 512])];
            tensor<fp32, [1, 128, 8, 64]> transpose_20 = transpose(perm = var_362, x = context_layer_13)[name = tensor<string, []>("transpose_20")];
            tensor<fp32, [1, 128, 512]> input_77 = reshape(shape = var_367, x = transpose_20)[name = tensor<string, []>("input_77")];
            tensor<fp32, [1, 128, 512]> linear_21 = linear(bias = model_encoder_layer_3_attention_output_dense_bias, weight = model_encoder_layer_3_attention_output_dense_weight, x = input_77)[name = tensor<string, []>("linear_21")];
            tensor<fp32, [1, 128, 512]> input_81 = add(x = linear_21, y = input_71)[name = tensor<string, []>("input_81")];
            tensor<int32, [1]> input_83_axes_0 = const()[name = tensor<string, []>("input_83_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp32, [1, 128, 512]> input_83 = layer_norm(axes = input_83_axes_0, beta = model_encoder_layer_3_attention_output_LayerNorm_bias, epsilon = var_12, gamma = model_encoder_layer_3_attention_output_LayerNorm_weight, x = input_81)[name = tensor<string, []>("input_83")];
            tensor<fp32, [1, 128, 4096]> linear_22 = linear(bias = linear_4_bias_0, weight = model_encoder_layer_3_mlp_gated_layers_weight, x = input_83)[name = tensor<string, []>("linear_22")];
            tensor<int32, [3]> input_85_begin_0 = const()[name = tensor<string, []>("input_85_begin_0"), val = tensor<int32, [3]>([0, 0, 0])];
            tensor<int32, [3]> input_85_end_0 = const()[name = tensor<string, []>("input_85_end_0"), val = tensor<int32, [3]>([1, 128, 2048])];
            tensor<bool, [3]> input_85_end_mask_0 = const()[name = tensor<string, []>("input_85_end_mask_0"), val = tensor<bool, [3]>([true, true, false])];
            tensor<fp32, [1, 128, 2048]> input_85 = slice_by_index(begin = input_85_begin_0, end = input_85_end_0, end_mask = input_85_end_mask_0, x = linear_22)[name = tensor<string, []>("input_85")];
            tensor<int32, [3]> non_gated_begin_0 = const()[name = tensor<string, []>("non_gated_begin_0"), val = tensor<int32, [3]>([0, 0, 2048])];
            tensor<int32, [3]> non_gated_end_0 = const()[name = tensor<string, []>("non_gated_end_0"), val = tensor<int32, [3]>([1, 128, 4096])];
            tensor<bool, [3]> non_gated_end_mask_0 = const()[name = tensor<string, []>("non_gated_end_mask_0"), val = tensor<bool, [3]>([true, true, true])];
            tensor<fp32, [1, 128, 2048]> non_gated = slice_by_index(begin = non_gated_begin_0, end = non_gated_end_0, end_mask = non_gated_end_mask_0, x = linear_22)[name = tensor<string, []>("non_gated")];
            tensor<string, []> var_391_mode_0 = const()[name = tensor<string, []>("op_391_mode_0"), val = tensor<string, []>("EXACT")];
            tensor<fp32, [1, 128, 2048]> var_391 = gelu(mode = var_391_mode_0, x = input_85)[name = tensor<string, []>("op_391")];
            tensor<fp32, [1, 128, 2048]> input_87 = mul(x = var_391, y = non_gated)[name = tensor<string, []>("input_87")];
            tensor<fp32, [1, 128, 512]> linear_23 = linear(bias = model_encoder_layer_3_mlp_wo_bias, weight = model_encoder_layer_3_mlp_wo_weight, x = input_87)[name = tensor<string, []>("linear_23")];
            tensor<fp32, [1, 128, 512]> input_91 = add(x = linear_23, y = input_83)[name = tensor<string, []>("input_91")];
            tensor<int32, [1]> hidden_states_axes_0 = const()[name = tensor<string, []>("hidden_states_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp32, [1, 128, 512]> last_hidden_state = layer_norm(axes = hidden_states_axes_0, beta = model_encoder_layer_3_mlp_layernorm_bias, epsilon = var_12, gamma = model_encoder_layer_3_mlp_layernorm_weight, x = input_91)[name = tensor<string, []>("hidden_states")];
            tensor<int32, [3]> input_93_begin_0 = const()[name = tensor<string, []>("input_93_begin_0"), val = tensor<int32, [3]>([0, 0, 0])];
            tensor<int32, [3]> input_93_end_0 = const()[name = tensor<string, []>("input_93_end_0"), val = tensor<int32, [3]>([1, 1, 512])];
            tensor<bool, [3]> input_93_end_mask_0 = const()[name = tensor<string, []>("input_93_end_mask_0"), val = tensor<bool, [3]>([true, false, true])];
            tensor<bool, [3]> input_93_squeeze_mask_0 = const()[name = tensor<string, []>("input_93_squeeze_mask_0"), val = tensor<bool, [3]>([false, true, false])];
            tensor<fp32, [1, 512]> input_93 = slice_by_index(begin = input_93_begin_0, end = input_93_end_0, end_mask = input_93_end_mask_0, squeeze_mask = input_93_squeeze_mask_0, x = last_hidden_state)[name = tensor<string, []>("input_93")];
            tensor<fp32, [1, 512]> linear_24 = linear(bias = model_pooler_dense_bias, weight = model_pooler_dense_weight, x = input_93)[name = tensor<string, []>("linear_24")];
            tensor<fp32, [1, 512]> pooler_output = tanh(x = linear_24)[name = tensor<string, []>("op_408")];
        } -> (last_hidden_state, pooler_output);
}